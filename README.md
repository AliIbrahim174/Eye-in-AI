# **Eye in AI**

**Eye in AI** is a smart glasses prototype designed to assist visually impaired individuals in navigating daily challenges. The device combines **image recognition** and **audio feedback** to help users recognize objects, faces, text, and colors. Using a **Raspberry Pi 3 Model B+** as its core, the system employs a camera to capture visuals, processes data with Python and AI models, and delivers output via audio.

---

## **Key Features**
- **Object Recognition**: Identifies objects and announces their names.
- **Face Recognition**: Recognizes people and informs the user of their identity.
- **Currency Detection**: Detects and announces currency denominations.
- **Text-to-Speech**: Reads text in multiple languages using OCR (Optical Character Recognition).
- **Color Detection**: Identifies and announces colors in the environment.

---

## **Technologies Used**
- **Hardware**: Raspberry Pi 3 Model B+, Raspberry Pi Camera, and speakers.
- **Programming**: Python, AI libraries like TensorFlow.
- **AI Training**: Google Teachable Machine for object and face detection.

---

## **Achievements**
- Successfully tested on real-world objects, faces, and currencies.
- Demonstrated high accuracy in text and color detection.
- Received recognition in multiple competitions, including Nile UGEFR.

---

## **Future Goals**
- Integrate GPS for real-time location tracking.
- Expand to multi-language support and personalized data inputs via a companion app.
- Launch a startup to make **Eye in AI** accessible globally for the visually impaired.
